{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikunj.bedia\\OneDrive - Providence St. Joseph Health\\Hackathon\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import gradio as gr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"\"\"\n",
    "System settings:\n",
    "Tool use: enabled.\n",
    "\n",
    "Instructions:\n",
    "- You are an AI medical assistant responsible for helping patients complete an intake form for back pain through voice interaction.\n",
    "- Use the tools to fetch questions to pose.\n",
    "- Start by greeting the user and calling the get_next_question tool without a currentPageId to get the first question from the root page.\n",
    "- After presenting each question to the user, wait for their response.\n",
    "- Use the get_next_question tool again with the current pageId to fetch the next question.\n",
    "- If a question has multiple choice options, present them clearly to the user and wait for their selection.\n",
    "- If the tool returns END-OF-FORM-QUESTIONS, conclude the intake process and thank the user.\n",
    "- Speak clearly and professionally, as if you were a medical professional conducting an intake interview.\n",
    "- If the user asks for clarification or has questions, respond helpfully while staying focused on completing the intake form.\n",
    "- Use other available tools as needed to enhance the interaction or gather additional information.\n",
    "- Do not attempt to process or interpret the user's responses within the tool call. Simply present the questions and options as provided by the tool.\n",
    "\n",
    "Personality:\n",
    "- Be professional, patient, and empathetic\n",
    "- Speak clearly and at a moderate pace\n",
    "- Use a calm and reassuring tone\n",
    "\n",
    "Remember: Your primary goal is to guide the user through the intake form for back pain by presenting questions. Do not make assumptions about the user's condition or provide medical advice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonraw=open(\"Async Care - Back Pain copy.json\")\n",
    "asyncCareBackPainData=json.load(jsonraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_question(currentPageId=None, selectedOption=None):\n",
    "    jsonData = asyncCareBackPainData  # assuming asyncCareBackPainData is already defined\n",
    "    nextPageId = \"\"\n",
    "\n",
    "    if currentPageId is None:\n",
    "        nextPageId = jsonData.get(\"algorithmRootPageId\",\"\")\n",
    "    elif selectedOption and \"link\" in selectedOption:\n",
    "        nextPageId = jsonData[\"nameToPageId\"].get(selectedOption[\"link\"], \"\")\n",
    "    elif jsonData[\"pages\"].get(currentPageId, {}).get(\"next_link\"):\n",
    "        nextLink = jsonData[\"pages\"][currentPageId][\"next_link\"]\n",
    "        if nextLink == \"END\":\n",
    "            return {\"tool_response\": \"END-OF-FORM-QUESTIONS\"}\n",
    "        if isinstance(nextLink, str):\n",
    "            nextPageId = jsonData[\"nameToPageId\"].get(nextLink, \"\")\n",
    "    else:\n",
    "        nextPageId = currentPageId\n",
    "\n",
    "    if not nextPageId:\n",
    "        return {\"error\": \"No next question found\"}\n",
    "\n",
    "    nextPage = jsonData[\"pages\"].get(nextPageId, {})\n",
    "\n",
    "    return {\n",
    "        \"pageId\": nextPageId,\n",
    "        \"questions\": nextPage.get(\"questions\", [])\n",
    "        # \"content\": nextPage.get(\"content\", None)  # Uncomment if needed\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\":\n",
    "        {\n",
    "          \"name\": 'get_next_question',\n",
    "          \"description\":'Fetches the next set of questions to ask the user for their medical concerns.',\n",
    "          \"parameters\": \n",
    "          {\n",
    "            \"type\": 'object',\n",
    "            \"properties\": \n",
    "            {\n",
    "              \"currentPageId\": \n",
    "              {\n",
    "                \"type\": 'string',\n",
    "                \"description\":\n",
    "                  'The ID of the current page. If not provided, the root page will be used.',\n",
    "              },\n",
    "              \"selectedOption\": \n",
    "              {\n",
    "                \"type\": 'object',\n",
    "                \"properties\": \n",
    "                {\n",
    "                  \"id\": { \"type\": 'string' },\n",
    "                  \"text\": { \"type\": 'string' },\n",
    "                  \"link\": { \"type\": 'string' },\n",
    "                },\n",
    "                \"description\": 'The option selected by the user (if any)',\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    }  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oai-aurigenai-dev-02.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('azure_endpoint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AKvwpfcYvzgvuC68ysO8OhYJYTFEe', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm here to help you complete an intake form for your back pain. Let's get started with the first question.\\n\\nJust a moment, please.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lifpL68a23Kh8AOkgY9goHWD', function=Function(arguments='{}', name='get_next_question'), type='function')]), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1729552675, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=CompletionUsage(completion_tokens=42, prompt_tokens=399, total_tokens=441, completion_tokens_details=None, prompt_tokens_details=None), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv('azure_endpoint'), \n",
    "  api_key=os.getenv('api_key'), \n",
    "  api_version=\"2024-02-15-preview\"\n",
    ")\n",
    "\n",
    "  \n",
    "deployment_name = os.getenv('deployment_name')  # Replace with your model deployment name\n",
    "\n",
    "def predict(message, history):\n",
    "    history_openai_format = []\n",
    "    history_openai_format.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "    })\n",
    "    for msg in history:\n",
    "        history_openai_format.append(msg)\n",
    "    \n",
    "    history_openai_format.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message\n",
    "    })\n",
    "\n",
    "    # print(history_openai_format)\n",
    "  \n",
    "    response = client.chat.completions.create(model=deployment_name,\n",
    "    messages= history_openai_format,\n",
    "    temperature=1.0,\n",
    "    stream=False,\n",
    "    tools=tools)\n",
    "\n",
    "    print(response)\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    # partial_message = \"\"\n",
    "    # for chunk in response:\n",
    "    #     if chunk.choices[0].delta.content is not None:\n",
    "    #           partial_message = partial_message + chunk.choices[0].delta.content\n",
    "    #           yield partial_message\n",
    "\n",
    "gr.ChatInterface(predict, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
